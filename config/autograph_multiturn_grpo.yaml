hydra:
  searchpath:
    - file://verl/trainer/config

defaults:
  - ppo_trainer
  - _self_

data:
  max_prompt_length: 1024
  max_response_length: 1024
  train_batch_size: 256
  return_raw_chat: True
  shuffle: False

actor_rollout_ref:
  hybrid_engine: True
  rollout:
    name: sglang_async
    multi_turn:
      enable: True
    use_api: True
    rag_method: subgraph
    text_linking: False
    freeze_answer_api: False
    set_llm_judge_model: False
    llm_judge_model_name: Qwen/Qwen2.5-7B-Instruct # LLM model name for judging the generated answer
    iterative: False
    tight: False
    reward_function: deducible_reward # available: f1_reward, deducible_reward, recall_reward
    filter_repetition_rollout: False # Whether filter out the excessive repetition in rollout stage
    filter_repetition_threshold: 0.9 # Threshold for filtering excessive repetition in rollout stage
custom_reward_function:
  reward_kwargs:
    triple_repetition_penalty: 0.0